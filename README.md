# üåæ Classifica√ß√£o de Gr√£os com Machine Learning (CRISP-DM)

**FIAP - Fase 4 - Cap√≠tulo 3: Da Terra ao C√≥digo**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1q_dA4_s58MoirCRGXitxJrriDpr2US8e?usp=sharing)

## üë• Integrantes do Grupo

* **Giovani Saavedra** - RM566797
* **Marcio Elifas** - RM567871
* **Felipe Bernardo Papeleo de Oliveira** - RM567782

---

## 1. üéØ Objetivo do Projeto

O objetivo desta atividade √© aplicar a metodologia **CRISP-DM** (Cross Industry Standard Process for Data Mining) para desenvolver um modelo de aprendizado de m√°quina capaz de classificar automaticamente variedades de gr√£os de trigo.

Em cooperativas agr√≠colas, essa classifica√ß√£o √© frequentemente manual, o que √© sujeito a erros e lentid√£o. Automatizar esse processo aumenta a efici√™ncia e a precis√£o da triagem.

Utilizamos o **"Seeds Dataset"** (do UCI Machine Learning Repository), que cont√©m medi√ß√µes geom√©tricas de gr√£os pertencentes a tr√™s variedades:
1. **Kama**
2. **Rosa**
3. **Canadian**

---

## 2. üîç Entendimento e An√°lise dos Dados (Data Understanding)

A primeira etapa do projeto consistiu na importa√ß√£o e an√°lise explorat√≥ria dos dados. O dataset original (`seeds_dataset.txt`) n√£o possui cabe√ßalho, portanto, definimos manualmente as colunas baseadas na documenta√ß√£o oficial:
* √Årea, Per√≠metro, Compacidade, Comprimento do N√∫cleo, Largura do N√∫cleo, Coeficiente de Assimetria e Comprimento do Sulco.

### Principais An√°lises Realizadas:
* **Estat√≠sticas Descritivas:** C√°lculo de m√©dia, desvio padr√£o e quartis para entender a dispers√£o dos dados.
* **Matriz de Correla√ß√£o:** Identificamos que vari√°veis como *√Årea*, *Per√≠metro* e *Comprimento do N√∫cleo* possuem correla√ß√£o positiva muito forte (pr√≥xima de 1.0), o que √© esperado fisicamente.
* **Visualiza√ß√£o Gr√°fica:** Utilizamos *Pairplots* e *Heatmaps* para observar que as classes possuem separa√ß√µes visuais claras em algumas dimens√µes, facilitando o trabalho dos algoritmos de classifica√ß√£o.

---

## 3. ‚öôÔ∏è Pr√©-processamento (Data Preparation)

Para garantir que os modelos performem corretamente, aplicamos as seguintes transforma√ß√µes nos dados:

1. **Separa√ß√£o de Dados:** Dividimos o dataset em conjuntos de **Treino (70%)** e **Teste (30%)**. Utilizamos estratifica√ß√£o (`stratify`) para garantir que a propor√ß√£o das tr√™s classes de trigo fosse mantida id√™ntica em ambos os conjuntos.
2. **Padroniza√ß√£o (Feature Scaling):** Aplicamos o `StandardScaler`.
    * *Por que?* Algoritmos baseados em dist√¢ncia (como KNN e SVM) s√£o sens√≠veis √† escala. A vari√°vel "√Årea" (ex: 15.0) √© numericamente muito maior que a "Assimetria" (ex: 0.8). Sem padroniza√ß√£o, o modelo daria peso excessivo √† √Årea. A padroniza√ß√£o coloca todas as vari√°veis na mesma escala matem√°tica.

---

## 4. ü§ñ Modelagem (Modeling)

Implementamos e comparamos tr√™s algoritmos de classifica√ß√£o distintos para validar qual abordagem se adapta melhor ao problema:

### 1. K-Nearest Neighbors (KNN)
* **L√≥gica:** Classifica o gr√£o baseando-se na classe dos vizinhos mais pr√≥ximos no espa√ßo geom√©trico.
* **Resultado:** Demonstrou alta efic√°cia, pois gr√£os da mesma esp√©cie tendem a ter medidas agrupadas.

### 2. Support Vector Machine (SVM)
* **L√≥gica:** Busca tra√ßar hiperplanos que separam as classes com a maior margem poss√≠vel.
* **Configura√ß√£o Inicial:** Kernel Linear.

### 3. Random Forest
* **L√≥gica:** Cria uma "floresta" de √°rvores de decis√£o e define a classe por vota√ß√£o majorit√°ria.
* **Vantagem:** √â robusto e fornece insights sobre a import√¢ncia de cada caracter√≠stica (feature importance).

---

## 5. üöÄ Otimiza√ß√£o e "Ir Al√©m"

Para superar a performance dos modelos base, aplicamos a t√©cnica de **Otimiza√ß√£o de Hiperpar√¢metros** utilizando o `GridSearchCV` no modelo SVM.

* **Par√¢metros testados:**
    * `C`: [0.1, 1, 10, 100] (Penalidade de erro)
    * `gamma`: [1, 0.1, 0.01, 0.001] (Coeficiente do kernel)
    * `kernel`: ['rbf', 'linear'] (Tipo de separa√ß√£o)

O GridSearch testou todas as combina√ß√µes matematicamente poss√≠veis para encontrar a configura√ß√£o √≥tima para este dataset espec√≠fico.

---

## 6. üìà Interpreta√ß√£o dos Resultados e Insights de Neg√≥cio

Atendendo ao objetivo de automatizar a triagem manual em cooperativas, realizamos uma an√°lise aprofundada dos resultados obtidos pelos modelos:

### 1. Desempenho Comparativo
* **SVM e Random Forest:** Ambos apresentaram desempenho superior (geralmente acima de 92% de acur√°cia). O **SVM com Kernel Linear** se destacou, indicando que as caracter√≠sticas f√≠sicas dos gr√£os possuem separa√ß√£o linear clara em um espa√ßo multidimensional.
* **KNN:** Embora eficaz, teve desempenho ligeiramente inferior, provavelmente devido √† sensibilidade a *outliers* ou fronteiras de decis√£o menos definidas entre gr√£os de tamanhos intermedi√°rios.

### 2. An√°lise da Matriz de Confus√£o (Onde o modelo erra?)
Ao analisar os erros, percebemos um padr√£o comportamental consistente com a realidade f√≠sica:
* **Variedade Rosa:** O modelo acerta quase 100% dos casos. **Motivo:** Esta √© a variedade fisicamente maior (maior √°rea e per√≠metro). √â f√°cil para a m√°quina (e para humanos) distingui-la das demais.
* **Confus√£o Kama vs. Canadian:** A maioria dos erros do modelo ocorre entre estas duas variedades. **Insight:** Isso revela que estas esp√©cies possuem caracter√≠sticas geom√©tricas muito similares. No processo manual, √© prov√°vel que especialistas humanos tamb√©m cometam erros justamente nessas duas classes, o que justifica o uso da IA para reduzir a fadiga e padronizar a decis√£o.

### 3. Impacto no Neg√≥cio (A Solu√ß√£o para a Cooperativa)
Conectando os dados ao problema real da cooperativa agr√≠cola:
* **Efici√™ncia Operacional:** O modelo √© capaz de classificar centenas de gr√£os em milissegundos, tarefa que levaria minutos ou horas para um humano.
* **Redu√ß√£o de Custo:** A automa√ß√£o permite que os especialistas foquem em tarefas de maior valor agregado, deixando a triagem repetitiva para o algoritmo.
* **Confiabilidade:** A consist√™ncia do modelo (acur√°cia > 90%) garante que a padroniza√ß√£o dos lotes de trigo seja mantida, valorizando o produto final da cooperativa no mercado.

### Veredito Final
A implementa√ß√£o do modelo **SVM Otimizado** √© a recomenda√ß√£o final para a solu√ß√£o tecnol√≥gica, pois equilibra alta precis√£o com baixo custo computacional, resolvendo o gargalo de classifica√ß√£o manual da cooperativa.
---

## üíª Como Executar o Projeto

Voc√™ pode visualizar e executar o c√≥digo diretamente no navegador atrav√©s do Google Colab, ou rodar localmente.

### Op√ß√£o 1: Google Colab
Clique no badge abaixo:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1q_dA4_s58MoirCRGXitxJrriDpr2US8e?usp=sharing)

### Op√ß√£o 2: Localmente
1. Clone o reposit√≥rio.
2. Instale as depend√™ncias:
   ```bash
   pip install pandas numpy matplotlib seaborn scikit-learn gdown

