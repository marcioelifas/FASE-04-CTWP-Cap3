# üåæ Classifica√ß√£o de Gr√£os com Machine Learning (CRISP-DM)

**FIAP - Fase 4 - Cap√≠tulo 3: Da Terra ao C√≥digo**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1q_dA4_s58MoirCRGXitxJrriDpr2US8e?usp=sharing)

## üë• Integrantes do Grupo

* **Giovani Saavedra** - RM566797
* **Marcio Elifas** - RM567871
* **Felipe Bernardo Papeleo de Oliveira** - RM567782

---

## 1. üéØ Objetivo do Projeto

O objetivo desta atividade √© aplicar a metodologia **CRISP-DM** (Cross Industry Standard Process for Data Mining) para desenvolver um modelo de aprendizado de m√°quina capaz de classificar automaticamente variedades de gr√£os de trigo.

Em cooperativas agr√≠colas, essa classifica√ß√£o √© frequentemente manual, o que √© sujeito a erros e lentid√£o. Automatizar esse processo aumenta a efici√™ncia e a precis√£o da triagem.

Utilizamos o **"Seeds Dataset"** (do UCI Machine Learning Repository), que cont√©m medi√ß√µes geom√©tricas de gr√£os pertencentes a tr√™s variedades:
1. **Kama**
2. **Rosa**
3. **Canadian**

---

## 2. üîç Entendimento e An√°lise dos Dados (Data Understanding)

A primeira etapa do projeto consistiu na importa√ß√£o e an√°lise explorat√≥ria dos dados. O dataset original (`seeds_dataset.txt`) n√£o possui cabe√ßalho, portanto, definimos manualmente as colunas baseadas na documenta√ß√£o oficial:
* √Årea, Per√≠metro, Compacidade, Comprimento do N√∫cleo, Largura do N√∫cleo, Coeficiente de Assimetria e Comprimento do Sulco.

### Principais An√°lises Realizadas:
* **Estat√≠sticas Descritivas:** C√°lculo de m√©dia, desvio padr√£o e quartis para entender a dispers√£o dos dados.
* **Matriz de Correla√ß√£o:** Identificamos que vari√°veis como *√Årea*, *Per√≠metro* e *Comprimento do N√∫cleo* possuem correla√ß√£o positiva muito forte (pr√≥xima de 1.0), o que √© esperado fisicamente.
* **Visualiza√ß√£o Gr√°fica:** Utilizamos *Pairplots* e *Heatmaps* para observar que as classes possuem separa√ß√µes visuais claras em algumas dimens√µes, facilitando o trabalho dos algoritmos de classifica√ß√£o.

---

## 3. ‚öôÔ∏è Pr√©-processamento (Data Preparation)

Para garantir que os modelos performem corretamente, aplicamos as seguintes transforma√ß√µes nos dados:

1. **Separa√ß√£o de Dados:** Dividimos o dataset em conjuntos de **Treino (70%)** e **Teste (30%)**. Utilizamos estratifica√ß√£o (`stratify`) para garantir que a propor√ß√£o das tr√™s classes de trigo fosse mantida id√™ntica em ambos os conjuntos.
2. **Padroniza√ß√£o (Feature Scaling):** Aplicamos o `StandardScaler`.
    * *Por que?* Algoritmos baseados em dist√¢ncia (como KNN e SVM) s√£o sens√≠veis √† escala. A vari√°vel "√Årea" (ex: 15.0) √© numericamente muito maior que a "Assimetria" (ex: 0.8). Sem padroniza√ß√£o, o modelo daria peso excessivo √† √Årea. A padroniza√ß√£o coloca todas as vari√°veis na mesma escala matem√°tica.

---

## 4. ü§ñ Modelagem (Modeling)

Implementamos e comparamos tr√™s algoritmos de classifica√ß√£o distintos para validar qual abordagem se adapta melhor ao problema:

### 1. K-Nearest Neighbors (KNN)
* **L√≥gica:** Classifica o gr√£o baseando-se na classe dos vizinhos mais pr√≥ximos no espa√ßo geom√©trico.
* **Resultado:** Demonstrou alta efic√°cia, pois gr√£os da mesma esp√©cie tendem a ter medidas agrupadas.

### 2. Support Vector Machine (SVM)
* **L√≥gica:** Busca tra√ßar hiperplanos que separam as classes com a maior margem poss√≠vel.
* **Configura√ß√£o Inicial:** Kernel Linear.

### 3. Random Forest
* **L√≥gica:** Cria uma "floresta" de √°rvores de decis√£o e define a classe por vota√ß√£o majorit√°ria.
* **Vantagem:** √â robusto e fornece insights sobre a import√¢ncia de cada caracter√≠stica (feature importance).

---

## 5. üöÄ Otimiza√ß√£o e "Ir Al√©m"

Para superar a performance dos modelos base, aplicamos a t√©cnica de **Otimiza√ß√£o de Hiperpar√¢metros** utilizando o `GridSearchCV` no modelo SVM.

* **Par√¢metros testados:**
    * `C`: [0.1, 1, 10, 100] (Penalidade de erro)
    * `gamma`: [1, 0.1, 0.01, 0.001] (Coeficiente do kernel)
    * `kernel`: ['rbf', 'linear'] (Tipo de separa√ß√£o)

O GridSearch testou todas as combina√ß√µes matematicamente poss√≠veis para encontrar a configura√ß√£o √≥tima para este dataset espec√≠fico.

---

## 6. üìä Conclus√£o e Insights

Ap√≥s a execu√ß√£o dos testes e avalia√ß√£o das matrizes de confus√£o, conclu√≠mos que:

1. **Alta Acur√°cia:** √â poss√≠vel classificar variedades de trigo com precis√£o superior a 90% utilizando apenas suas medidas geom√©tricas.
2. **Distin√ß√£o das Classes:** A variedade **Rosa** √© a mais f√°cil de identificar, geralmente apresentando √°rea e per√≠metro maiores. As variedades **Kama** e **Canadian** possuem algumas sobreposi√ß√µes sutis, onde ocorreram os poucos erros de classifica√ß√£o.
3. **Import√¢ncia do Pr√©-processamento:** A normaliza√ß√£o dos dados foi um passo cr√≠tico para o sucesso dos modelos KNN e SVM.

---

## üíª Como Executar o Projeto

Voc√™ pode visualizar e executar o c√≥digo diretamente no navegador atrav√©s do Google Colab, ou rodar localmente.

### Op√ß√£o 1: Google Colab
Clique no badge abaixo:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1q_dA4_s58MoirCRGXitxJrriDpr2US8e?usp=sharing)

### Op√ß√£o 2: Localmente
1. Clone o reposit√≥rio.
2. Instale as depend√™ncias:
   ```bash
   pip install pandas numpy matplotlib seaborn scikit-learn gdown

